{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import display\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data = pd.read_excel('C:/Users/GANESHA/Downloads/project/Data/INX_Future_Inc_Employee_Performance_CDS_Project2_Data_V1.8.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data['Department_Role'] = emp_data['EmpJobRole'] + \" - \" + emp_data['EmpDepartment']\n",
    "emp_data_columns = emp_data.columns.values\n",
    "X = emp_data[emp_data_columns[0:29]]\n",
    "Y = emp_data['PerformanceRating']\n",
    "X.drop('PerformanceRating', axis=1, inplace=True)\n",
    "X.drop('EmpNumber', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 6\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Gender = pd.get_dummies(X['Gender'], drop_first = False , sparse = True)\n",
    "X_Education = pd.get_dummies(X['EducationBackground'], drop_first = False , sparse = True)\n",
    "X_MaritalStatus = pd.get_dummies(X['MaritalStatus'], drop_first = False , sparse = True)\n",
    "X_EmpDepartment = pd.get_dummies(X['EmpDepartment'], drop_first = False , sparse = True)\n",
    "X_EmpJobRole = pd.get_dummies(X['EmpJobRole'], drop_first = False , sparse = True)\n",
    "X_BusinessTravelFrequency = pd.get_dummies(X['BusinessTravelFrequency'], drop_first = False , sparse = True)\n",
    "X_OverTime = pd.get_dummies(X['OverTime'], drop_first = False, sparse = True)\n",
    "X_Department_Role = pd.get_dummies(X['Department_Role'], drop_first = False , sparse = True)\n",
    "X_Attrition = pd.get_dummies(X['Attrition'], drop_first = False, sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 27)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Gender'] = X_Gender\n",
    "X['EducationBackground'] = X_Education\n",
    "X['MaritalStatus'] = X_MaritalStatus\n",
    "X['EmpDepartment'] = X_EmpDepartment\n",
    "X['EmpJobRole'] = X_EmpJobRole\n",
    "X['BusinessTravelFrequency'] = X_BusinessTravelFrequency\n",
    "X['OverTime'] = X_OverTime\n",
    "X['Department_Role'] = X_Department_Role\n",
    "X['Attrition'] = X_Attrition\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting data into Xtran, Xtest , Y train and Y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3,random_state = 0, stratify = emp_data['PerformanceRating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating RandomSearch for tunning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearch(object):\n",
    "    \n",
    "    def __init__(self,X_train,y_train,model,hyperparameters):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model = model\n",
    "        self.hyperparameters = hyperparameters\n",
    "        \n",
    "    def RandomSearch(self):\n",
    "        # Create randomized search 10-fold cross validation and 100 iterations\n",
    "        cv = 10\n",
    "        clf = RandomizedSearchCV(self.model,\n",
    "                                 self.hyperparameters,\n",
    "                                 random_state=1,\n",
    "                                 n_iter=100,\n",
    "                                 cv=cv,\n",
    "                                 verbose=0,\n",
    "                                 n_jobs=-1,\n",
    "                                 )\n",
    "        # Fit randomized search\n",
    "        best_model = clf.fit(self.X_train, self.y_train)\n",
    "        message = (best_model.best_score_, best_model.best_params_)\n",
    "        print(\"Best: %f using %s\" % (message))\n",
    "\n",
    "        return best_model,best_model.best_params_\n",
    "    \n",
    "    def BestModelPridict(self,X_test):\n",
    "        \n",
    "        best_model,_ = self.RandomSearch()\n",
    "        pred = best_model.predict(X_test)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining GridSearch for hyper tunning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearch(object):\n",
    "    \n",
    "    def __init__(self,X_train,y_train,model,hyperparameters):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model = model\n",
    "        self.hyperparameters = hyperparameters\n",
    "        \n",
    "    def GridSearch(self):\n",
    "        # Create randomized search 10-fold cross validation and 100 iterations\n",
    "        cv = 10\n",
    "        clf = GridSearchCV(self.model,\n",
    "                                 self.hyperparameters,\n",
    "                                 cv=cv,\n",
    "                                 verbose=0,\n",
    "                                 n_jobs=-1,\n",
    "                                 )\n",
    "        # Fit randomized search\n",
    "        best_model = clf.fit(self.X_train, self.y_train)\n",
    "        message = (best_model.best_score_, best_model.best_params_)\n",
    "        print(\"Best: %f using %s\" % (message))\n",
    "\n",
    "        return best_model,best_model.best_params_\n",
    "    \n",
    "    def BestModelPridict(self,X_test):\n",
    "        \n",
    "        best_model,_ = self.GridSearch()\n",
    "        pred = best_model.predict(X_test)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floatingDecimals(f_val, dec=3):\n",
    "        prc = \"{:.\"+str(dec)+\"f}\" #first cast decimal as str\n",
    "    #     print(prc) #str format output is {:.3f}\n",
    "        return float(prc.format(f_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression as ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.770238 using {'C': 2.7460037107263346, 'penalty': 'l1'}\n",
      "prediction on test set is: 0.7666667\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "LR_RandSearch = RandomSearch(X_train,Y_train,model,hyperparameters)\n",
    "# LR_best_model,LR_best_params = LR_RandSearch.RandomSearch()\n",
    "Prediction_LR = LR_RandSearch.BestModelPridict(X_test)\n",
    "print('prediction on test set is:' ,floatingDecimals((Y_test == Prediction_LR).mean(),7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using KNN as ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_KNN = KNeighborsClassifier()\n",
    "neighbors = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "param_grid = dict(n_neighbors=neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.733333 using {'n_neighbors': 12}\n",
      "prediction on test set is: 0.7333333\n"
     ]
    }
   ],
   "source": [
    "KNN_GridSearch = GridSearch(X_train,Y_train,model_KNN,param_grid)\n",
    "Prediction_KNN = KNN_GridSearch.BestModelPridict(X_test)\n",
    "print('prediction on test set is:' ,floatingDecimals((Y_test == Prediction_KNN).mean(),7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Decission Tree Classifier as ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "max_depth_value = [3, None]\n",
    "max_features_value =  randint(1, 4)\n",
    "min_samples_leaf_value = randint(1, 4)\n",
    "criterion_value = [\"gini\", \"entropy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(max_depth = max_depth_value,\n",
    "                  max_features = max_features_value,\n",
    "                  min_samples_leaf = min_samples_leaf_value,\n",
    "                  criterion = criterion_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.803571 using {'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'min_samples_leaf': 3}\n",
      "prediction on test set is: 0.7166667\n"
     ]
    }
   ],
   "source": [
    "model_CART = DecisionTreeClassifier()\n",
    "CART_RandSearch = RandomSearch(X_train,Y_train,model_CART,param_grid)\n",
    "Prediction_CART = CART_RandSearch.BestModelPridict(X_test)\n",
    "print('prediction on test set is:' ,floatingDecimals((Y_test == Prediction_CART).mean(),7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM as ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "kernel_values = [ 'linear' , 'poly' , 'rbf' , 'sigmoid' ]\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model_SVC = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.784524 using {'C': 0.5, 'kernel': 'linear'}\n",
      "prediction on test set is: 0.7888889\n"
     ]
    }
   ],
   "source": [
    "SVC_GridSearch = GridSearch(X_train,Y_train,model_SVC,param_grid)\n",
    "Prediction_SVC = SVC_GridSearch.BestModelPridict(X_test)\n",
    "print('prediction on test set is:' ,floatingDecimals((Y_test == Prediction_SVC).mean(),7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AdaBoost classifier as ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_value = [.01,.05,.1,.5,1]\n",
    "n_estimators_value = [50,100,150,200,250,300,500]\n",
    "\n",
    "param_grid = dict(learning_rate=learning_rate_value, n_estimators=n_estimators_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.845238 using {'learning_rate': 0.05, 'n_estimators': 250}\n",
      "prediction on test set is: 0.8361111\n"
     ]
    }
   ],
   "source": [
    "model_Ad = AdaBoostClassifier()\n",
    "Ad_GridSearch = GridSearch(X_train,Y_train,model_Ad,param_grid)\n",
    "Prediction_Ad = Ad_GridSearch.BestModelPridict(X_test)\n",
    "print('prediction on test set is:' ,floatingDecimals((Y_test == Prediction_Ad).mean(),7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GradientBoostng Algorithm as ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_value = [.01,.05,.1,.5,1]\n",
    "n_estimators_value = [50,100,150,200,250,300,400,500,1000]\n",
    "\n",
    "param_grid = dict(learning_rate=learning_rate_value, n_estimators=n_estimators_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.909524 using {'learning_rate': 0.01, 'n_estimators': 150}\n",
      "prediction on test set is: 0.8944444\n"
     ]
    }
   ],
   "source": [
    "model_GB = GradientBoostingClassifier()\n",
    "GB_GridSearch = GridSearch(X_train,Y_train,model_GB,param_grid)\n",
    "Prediction_GB = GB_GridSearch.BestModelPridict(X_test)\n",
    "print('prediction on test set is:' ,floatingDecimals((Y_test == Prediction_GB).mean(),7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all models with tunned hyper parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C': 3.5055566091841532, 'penalty': 'l1'}\n",
    "model1 = LogisticRegression(**param)\n",
    "\n",
    "param = {'n_neighbors': 12}\n",
    "model2 = KNeighborsClassifier(**param)\n",
    "\n",
    "param = {'C': 0.5, 'kernel': 'linear'}\n",
    "model3 = SVC(**param)\n",
    "\n",
    "param = {'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 3}\n",
    "model4 = DecisionTreeClassifier(**param)\n",
    "\n",
    "param = {'learning_rate': 0.05, 'n_estimators': 250}\n",
    "model5 = AdaBoostClassifier(**param)\n",
    "\n",
    "param = {'learning_rate': 0.01, 'n_estimators': 150}\n",
    "model6 = GradientBoostingClassifier(**param)\n",
    "\n",
    "model7 = GaussianNB()\n",
    "\n",
    "model8 = RandomForestClassifier()\n",
    "\n",
    "model9 = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('LR',model1), ('KNN',model2), ('SVC',model3),\n",
    "              ('DT',model4), ('ADa',model5), ('GB',model6),\n",
    "              ('NB',model7), ('RF',model8),  ('ET',model9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train:  0.8322275814220335\n",
      "Accuracy on test: 0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, random_state=SEED)\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = cross_val_score(ensemble, X_train,Y_train, cv=kfold)\n",
    "print('Accuracy on train: ',results.mean())\n",
    "ensemble_model = ensemble.fit(X_train,Y_train)\n",
    "pred = ensemble_model.predict(X_test)\n",
    "print('Accuracy on test:' , (Y_test == pred).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
